[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Francis Chan",
    "section": "",
    "text": "I’m a senior at UCLA majoring in Statistics & Data Science. I enjoy solving problem, tackling complex challenges, and leveraging data to drive impactful descisions."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Francis Chan",
    "section": "Education",
    "text": "Education\nUniversity of California, Los Angeles | Los Angeles, CA\nB.S in Statistics & Data Science | Sept 2023 - June 2025\nDe Anza College | Cupertino, CA\nA.S in Mathematics | Sept 2021 - June 2023"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Francis Chan",
    "section": "Experience",
    "text": "Experience\nUCLA Housing | Front Desk Assistant\nJune 2024 - present"
  },
  {
    "objectID": "index.html#skill-sets",
    "href": "index.html#skill-sets",
    "title": "Francis Chan",
    "section": "Skill sets",
    "text": "Skill sets\n\nPython\n\nNumPy\nPandas\nMatplotlib\nScikit-learn\nTensorFlow\n\nR\n\nggplot2\nDplyr\nCaret\n\nMS Excel\n\nVLookup\nPivot Table\n\nGit\n\nGithub\n\nSQL\nTableau\nStata\nJava\nHTML5\nCSS\nC++"
  },
  {
    "objectID": "projects/project_3.html",
    "href": "projects/project_3.html",
    "title": "2023-2024 NBA Results Prediction",
    "section": "",
    "text": "This project aimed to predict the outcomes of NBA games during the 2023-2024 season using past game statistics. The objective was to develop a statistical model capable of estimating game results based on historical performance, team matchups, and engineered features. The primary challenge was structuring the data for predictive modeling, which involved extensive feature engineering and selection techniques.\n\n\n\n\nData Preprocessing:\n\nCleaned the dataset of 1,230 games, ensuring statistical integrity.\nReshaped data so each entry contained all relevant statistics for a single game rather than separate team-specific entries.\nStandardized numerical features to maintain consistency across different scales.\n\nFeature Engineering:\n\nCreated new variables such as block percentage and assist percentage to capture team performance more effectively.\nIntroduced a team instability metric, measuring performance variance across games to assess consistency.\nComputed weighted mean past statistics, giving greater importance to recent games, home/away status, and previous matchups.\nUsed relative statistical measures (e.g., raw difference, squared difference) to better contextualize team performance.\n\nFeature Selection:\n\nApplied L1-regularized Logistic Regression to identify the most informative variables.\nFurther refined the feature set through Principal Component Analysis (PCA) and forward selection, ultimately reducing the model to two key variables:\nA principal component combining point difference and field goal percentage.\nThe raw count of successful three-point shots.\n\nModeling and Evaluation:\n\nExperimented with various predictive models, including:\n\nLogistic Regression\nLinear and Radial Support Vector Machines (SVM)\nK-Nearest Neighbors (KNN)\nLinear and Quadratic Discriminant Analysis (LDA, QDA)\nRandom Forest\n\nTuned hyperparameters via grid search and cross-validation to optimize accuracy.\nFound Linear SVM to be the best-performing model, achieving a validation accuracy of 68.7%.\n\n\n\n\n\n\nSuccessfully built a predictive model with nearly 70% accuracy using only two key features.\nIdentified home/away performance weighting as a significant factor in prediction accuracy.\nDetermined that Random Forest performed poorly due to excessive feature reduction, which limited its effectiveness.\n\n\n\n\n\nThe current model relies on team-level statistics; incorporating individual player data and roster changes could improve predictions.\nPlaystyle categorization (e.g., defensive vs. offensive strategies) may enhance feature selection.\nExploring alternative matchup weighting schemes (e.g., team similarity metrics) could refine performance estimates.\nFurther expanding the dataset beyond a single season might enhance model generalizability.\n\n\n\n\n2023-2024 NBA Results Prediction"
  },
  {
    "objectID": "projects/project_3.html#summary",
    "href": "projects/project_3.html#summary",
    "title": "2023-2024 NBA Results Prediction",
    "section": "",
    "text": "This project aimed to predict the outcomes of NBA games during the 2023-2024 season using past game statistics. The objective was to develop a statistical model capable of estimating game results based on historical performance, team matchups, and engineered features. The primary challenge was structuring the data for predictive modeling, which involved extensive feature engineering and selection techniques.\n\n\n\n\nData Preprocessing:\n\nCleaned the dataset of 1,230 games, ensuring statistical integrity.\nReshaped data so each entry contained all relevant statistics for a single game rather than separate team-specific entries.\nStandardized numerical features to maintain consistency across different scales.\n\nFeature Engineering:\n\nCreated new variables such as block percentage and assist percentage to capture team performance more effectively.\nIntroduced a team instability metric, measuring performance variance across games to assess consistency.\nComputed weighted mean past statistics, giving greater importance to recent games, home/away status, and previous matchups.\nUsed relative statistical measures (e.g., raw difference, squared difference) to better contextualize team performance.\n\nFeature Selection:\n\nApplied L1-regularized Logistic Regression to identify the most informative variables.\nFurther refined the feature set through Principal Component Analysis (PCA) and forward selection, ultimately reducing the model to two key variables:\nA principal component combining point difference and field goal percentage.\nThe raw count of successful three-point shots.\n\nModeling and Evaluation:\n\nExperimented with various predictive models, including:\n\nLogistic Regression\nLinear and Radial Support Vector Machines (SVM)\nK-Nearest Neighbors (KNN)\nLinear and Quadratic Discriminant Analysis (LDA, QDA)\nRandom Forest\n\nTuned hyperparameters via grid search and cross-validation to optimize accuracy.\nFound Linear SVM to be the best-performing model, achieving a validation accuracy of 68.7%.\n\n\n\n\n\n\nSuccessfully built a predictive model with nearly 70% accuracy using only two key features.\nIdentified home/away performance weighting as a significant factor in prediction accuracy.\nDetermined that Random Forest performed poorly due to excessive feature reduction, which limited its effectiveness.\n\n\n\n\n\nThe current model relies on team-level statistics; incorporating individual player data and roster changes could improve predictions.\nPlaystyle categorization (e.g., defensive vs. offensive strategies) may enhance feature selection.\nExploring alternative matchup weighting schemes (e.g., team similarity metrics) could refine performance estimates.\nFurther expanding the dataset beyond a single season might enhance model generalizability.\n\n\n\n\n2023-2024 NBA Results Prediction"
  },
  {
    "objectID": "projects/project_1.html",
    "href": "projects/project_1.html",
    "title": "Banknote Authentication and Model Evaluation",
    "section": "",
    "text": "This project aimed to classify banknotes as genuine or counterfeit using machine learning models. The objective was to develop and compare different classifiers to determine the most accurate model for this task. The process involved data preprocessing, model training, evaluation, and performance analysis.\n\n\n\n\nData Preparation:\n\nLoaded the dataset and structured it into feature variables (X) and labels (y).\nStandardized feature variables for improved model performance.\nSplit the dataset into training and testing sets using a 70-30 ratio.\n\nModeling and Evaluation:\n\nTrained a Decision Tree classifier and evaluated its accuracy on both training and test sets.\nImplemented a Random Forest model with 51 estimators and a depth of 5, achieving higher accuracy compared to the Decision Tree.\nApplied a Gradient Boosting classifier with the same number of estimators and depth, which showed the highest training accuracy.\nAssessed model performance using accuracy scores and test error rates.\n\n\n\n\n\n\nThe Decision Tree model had a test accuracy of 96.36%, indicating moderate performance.\nThe Random Forest model improved accuracy to 99.51%, showing better generalization.\nThe Gradient Boosting model achieved a near-perfect accuracy of 99.27%, suggesting strong predictive capabilities.\nBoth Random Forest and Gradient Boosting significantly outperformed the Decision Tree in terms of generalization and error minimization.\nThis analysis demonstrated the effectiveness of ensemble methods like Random Forest and Gradient Boosting in reducing classification errors for banknote authentication.\n\n\n\n\nBanknote Authentication"
  },
  {
    "objectID": "projects/project_1.html#summary",
    "href": "projects/project_1.html#summary",
    "title": "Banknote Authentication and Model Evaluation",
    "section": "",
    "text": "This project aimed to classify banknotes as genuine or counterfeit using machine learning models. The objective was to develop and compare different classifiers to determine the most accurate model for this task. The process involved data preprocessing, model training, evaluation, and performance analysis.\n\n\n\n\nData Preparation:\n\nLoaded the dataset and structured it into feature variables (X) and labels (y).\nStandardized feature variables for improved model performance.\nSplit the dataset into training and testing sets using a 70-30 ratio.\n\nModeling and Evaluation:\n\nTrained a Decision Tree classifier and evaluated its accuracy on both training and test sets.\nImplemented a Random Forest model with 51 estimators and a depth of 5, achieving higher accuracy compared to the Decision Tree.\nApplied a Gradient Boosting classifier with the same number of estimators and depth, which showed the highest training accuracy.\nAssessed model performance using accuracy scores and test error rates.\n\n\n\n\n\n\nThe Decision Tree model had a test accuracy of 96.36%, indicating moderate performance.\nThe Random Forest model improved accuracy to 99.51%, showing better generalization.\nThe Gradient Boosting model achieved a near-perfect accuracy of 99.27%, suggesting strong predictive capabilities.\nBoth Random Forest and Gradient Boosting significantly outperformed the Decision Tree in terms of generalization and error minimization.\nThis analysis demonstrated the effectiveness of ensemble methods like Random Forest and Gradient Boosting in reducing classification errors for banknote authentication.\n\n\n\n\nBanknote Authentication"
  },
  {
    "objectID": "projects/project_2.html",
    "href": "projects/project_2.html",
    "title": "MNIST Handwritten Digit Recognition",
    "section": "",
    "text": "This project focused on improving the accuracy of handwritten digit recognition using the MNIST dataset. The objective was to enhance an existing model’s performance by implementing various optimization techniques. The goal was to increase accuracy from an initial baseline of 95% to nearly 99%.\n\n\n\n\nModel Optimization:\n\nUsed a pre-trained model as a baseline for comparison.\nAdjusted the MaxPooling2D layer’s strides parameter to (1,1) to reduce downsampling and capture more features.\nModified the Dropout rate to 0.05, ensuring more neurons remained active during training while preventing overfitting.\n\nTechniques Implemented:\n\nExperimented with different batch sizes and number of epochs to optimize training.\nEvaluated the effect of GPU vs. CPU performance on model training speed.\n\n\n\n\n\n\nSuccessfully improved the model’s accuracy from 95% to nearly 99%.\nApplied fine-tuned hyperparameters to create an optimized model with enhanced digit recognition capabilities.\nBalanced model complexity and generalization through strategic dropout settings and pooling adjustments.\n\n\n\n\nMNIST Handwritten Digit Recognition"
  },
  {
    "objectID": "projects/project_2.html#summary",
    "href": "projects/project_2.html#summary",
    "title": "MNIST Handwritten Digit Recognition",
    "section": "",
    "text": "This project focused on improving the accuracy of handwritten digit recognition using the MNIST dataset. The objective was to enhance an existing model’s performance by implementing various optimization techniques. The goal was to increase accuracy from an initial baseline of 95% to nearly 99%.\n\n\n\n\nModel Optimization:\n\nUsed a pre-trained model as a baseline for comparison.\nAdjusted the MaxPooling2D layer’s strides parameter to (1,1) to reduce downsampling and capture more features.\nModified the Dropout rate to 0.05, ensuring more neurons remained active during training while preventing overfitting.\n\nTechniques Implemented:\n\nExperimented with different batch sizes and number of epochs to optimize training.\nEvaluated the effect of GPU vs. CPU performance on model training speed.\n\n\n\n\n\n\nSuccessfully improved the model’s accuracy from 95% to nearly 99%.\nApplied fine-tuned hyperparameters to create an optimized model with enhanced digit recognition capabilities.\nBalanced model complexity and generalization through strategic dropout settings and pooling adjustments.\n\n\n\n\nMNIST Handwritten Digit Recognition"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Project",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nDiabetes Risk Prediction with Statistical Modeling\n\n\n\n\n\n\nR\n\n\nPrediction\n\n\nAnalysis\n\n\n\nThis project involves identifying key factors influencing diabetes.\n\n\n\n\n\nMar 20, 2025\n\n\nFrancis Chan\n\n\n\n\n\n\n\n\n\n\n\n\n2023-2024 NBA Results Prediction\n\n\n\n\n\n\nPython\n\n\nPrediction\n\n\n\nThis project involves preprocessing and predicting the NBA dataset.\n\n\n\n\n\nDec 13, 2024\n\n\nFrancis Chan\n\n\n\n\n\n\n\n\n\n\n\n\nBanknote Authentication and Model Evaluation\n\n\n\n\n\n\nPython\n\n\nClassification\n\n\n\nThis project involves classifying genuine or counterfeit banknotes.\n\n\n\n\n\nNov 10, 2024\n\n\nFrancis Chan\n\n\n\n\n\n\n\n\n\n\n\n\nMNIST Handwritten Digit Recognition\n\n\n\n\n\n\nPython\n\n\nClassification\n\n\n\nThis project aims to improve the classification model.\n\n\n\n\n\nAug 17, 2024\n\n\nFrancis Chan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project_4.html",
    "href": "projects/project_4.html",
    "title": "Diabetes Risk Prediction with Statistical Modeling",
    "section": "",
    "text": "This project aimed to identify key factors influencing diabetes diagnosis by analyzing a dataset of 9,538 medical records. The study focused on understanding the relationships between body mass index (BMI), glycated hemoglobin (HbA1c), family history, and age in predicting diabetes risk. Through statistical modeling and feature selection, the goal was to develop an effective predictive model for diabetes classification.\n\n\n\n\nData Preprocessing:\n\nUtilized a secondary dataset containing demographic, lifestyle, and biometric health data.\nThe dataset required minimal cleaning, with no missing values or outliers to remove.\nChecked for multicollinearity using Variance Inflation Factor (VIF), revealing strong correlation between HbA1c and glucose, leading to the removal of glucose from the model.\n\nFeature Selection:\n\nEmployed stepwise regression to identify the most significant predictors.\nFinal selected variables: Age, BMI, HbA1c, and Family History.\nUsed ANOVA to confirm that the reduced model performed comparably to the full model, ensuring efficiency without sacrificing predictive power.\n\nModeling and Evaluation:\n\nImplemented logistic regression as the primary predictive model.\nPerformed train-test split (70%-30%) and evaluated the model using a confusion matrix, achieving a 97% accuracy.\nConducted 5-fold cross-validation, with performance metrics:\n\nRoot Mean Squared Error (RMSE): 0.146\nR-squared: 0.906 (indicating the model explains 90.6% of variance in diabetes outcomes)\nMean Absolute Error (MAE): 0.04\n\nPlotted the Receiver Operating Characteristic (ROC) curve, yielding an AUC of 0.99, reflecting high classification performance.\n\nFurther Exploration:\n\nFamily History & Diabetes Risk:\n\nWhile family history was statistically insignificant in the model, visualizations revealed that individuals with a family history of diabetes had a higher proportion of diagnoses, suggesting an underlying influence.\n\nAge & Family History Interaction:\n\nAnalyzed diabetes cases across different age groups and found that family history remained a strong risk factor across all ages, whereas diabetes risk for individuals without family history increased significantly after age 50-60.\n\nBMI & HbA1C Interaction:\n\nFound that higher BMI and HbA1c levels corresponded to a greater likelihood of diabetes diagnosis, reinforcing their predictive importance.\n\n\n\n\n\n\n\nDeveloped a highly accurate logistic regression model for diabetes prediction.\nIdentified BMI, HbA1c, and Age as primary predictors, with family history as a potential modifier.\nDemonstrated that early monitoring of metabolic health (HbA1c, BMI) is critical in diabetes prevention.\n\n\n\n\n\nConfounders not included: The dataset lacked variables such as diet, exercise, and socioeconomic status, which could influence diabetes risk.\nMeasurement errors: Variability in medical recordings and instruments could introduce inconsistencies.\nFuture research directions:\n\nInvestigate gender-specific diabetes risks (e.g., male prevalence vs. female long-term complications).\nExplore BMI and gender interactions in diabetes risk.\nIncorporate player-specific statistics or historical trends to refine predictions.\n\n\n\n\n\nDiabetes Risk Prediction"
  },
  {
    "objectID": "projects/project_4.html#summary",
    "href": "projects/project_4.html#summary",
    "title": "Diabetes Risk Prediction with Statistical Modeling",
    "section": "",
    "text": "This project aimed to identify key factors influencing diabetes diagnosis by analyzing a dataset of 9,538 medical records. The study focused on understanding the relationships between body mass index (BMI), glycated hemoglobin (HbA1c), family history, and age in predicting diabetes risk. Through statistical modeling and feature selection, the goal was to develop an effective predictive model for diabetes classification.\n\n\n\n\nData Preprocessing:\n\nUtilized a secondary dataset containing demographic, lifestyle, and biometric health data.\nThe dataset required minimal cleaning, with no missing values or outliers to remove.\nChecked for multicollinearity using Variance Inflation Factor (VIF), revealing strong correlation between HbA1c and glucose, leading to the removal of glucose from the model.\n\nFeature Selection:\n\nEmployed stepwise regression to identify the most significant predictors.\nFinal selected variables: Age, BMI, HbA1c, and Family History.\nUsed ANOVA to confirm that the reduced model performed comparably to the full model, ensuring efficiency without sacrificing predictive power.\n\nModeling and Evaluation:\n\nImplemented logistic regression as the primary predictive model.\nPerformed train-test split (70%-30%) and evaluated the model using a confusion matrix, achieving a 97% accuracy.\nConducted 5-fold cross-validation, with performance metrics:\n\nRoot Mean Squared Error (RMSE): 0.146\nR-squared: 0.906 (indicating the model explains 90.6% of variance in diabetes outcomes)\nMean Absolute Error (MAE): 0.04\n\nPlotted the Receiver Operating Characteristic (ROC) curve, yielding an AUC of 0.99, reflecting high classification performance.\n\nFurther Exploration:\n\nFamily History & Diabetes Risk:\n\nWhile family history was statistically insignificant in the model, visualizations revealed that individuals with a family history of diabetes had a higher proportion of diagnoses, suggesting an underlying influence.\n\nAge & Family History Interaction:\n\nAnalyzed diabetes cases across different age groups and found that family history remained a strong risk factor across all ages, whereas diabetes risk for individuals without family history increased significantly after age 50-60.\n\nBMI & HbA1C Interaction:\n\nFound that higher BMI and HbA1c levels corresponded to a greater likelihood of diabetes diagnosis, reinforcing their predictive importance.\n\n\n\n\n\n\n\nDeveloped a highly accurate logistic regression model for diabetes prediction.\nIdentified BMI, HbA1c, and Age as primary predictors, with family history as a potential modifier.\nDemonstrated that early monitoring of metabolic health (HbA1c, BMI) is critical in diabetes prevention.\n\n\n\n\n\nConfounders not included: The dataset lacked variables such as diet, exercise, and socioeconomic status, which could influence diabetes risk.\nMeasurement errors: Variability in medical recordings and instruments could introduce inconsistencies.\nFuture research directions:\n\nInvestigate gender-specific diabetes risks (e.g., male prevalence vs. female long-term complications).\nExplore BMI and gender interactions in diabetes risk.\nIncorporate player-specific statistics or historical trends to refine predictions.\n\n\n\n\n\nDiabetes Risk Prediction"
  }
]